{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "id": "lEMwJOsbDW1k",
        "outputId": "08f68cf2-d5f1-4ac3-cab4-3061b13f0603"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# read_data and make train and test data for example\n",
        "# https://www.kaggle.com/datasets/arnabchaki/data-science-salaries-2023\n",
        "def read_data():\n",
        "    df = pd.read_csv(\"ds_salaries.csv\")\n",
        "    df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
        "    return df_train.reset_index(drop=True), df_test.reset_index(drop=True)\n",
        "\n",
        "df_train, df_test = read_data()\n",
        "print(df_train.shape, df_test.shape)\n",
        "df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# make baseblock for funciton. Update by class inheritance.\n",
        "class base():\n",
        "    def fit(self, input_df: pd.DataFrame):\n",
        "        return self.transform(input_df)\n",
        "    def transform(self, input_df: pd.DataFrame)->pd.DataFrame:\n",
        "        raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUYp3KdtQeFY"
      },
      "outputs": [],
      "source": [
        "## 要修正\n",
        "# # 時間特徴量の簡易処理（あれば。事前に時間特徴量にparse_datesで変換しておく。）\n",
        "# # 時間を分解\n",
        "# def sep_time(df, col, col2=0):\n",
        "#   df[col+\"_y\"]=df[col].dt.year\n",
        "#   df[col+\"_m\"]=df[col].dt.month\n",
        "#   df[col+\"_d\"]=df[col].dt.day\n",
        "#   if col2!=0:\n",
        "#     df[col2+\"_y\"]=df[col2].dt.year\n",
        "#     df[col2+\"_m\"]=df[col2].dt.month\n",
        "#     df[col2+\"_d\"]=df[col2].dt.day\n",
        "#     df[col+\"-\"+col2]=df[col] - df[col2]\n",
        "#   return df\n",
        "\n",
        "# def time_encode(df, col):\n",
        "#     # この方法だと場合によって最大値が変化するデータでは正確な値は出ない\n",
        "#     # 例：月の日数が30日や31日の場合がある\n",
        "#     df[col + '_cos'] = np.cos(2 * np.pi * df[col] / df[col].max())\n",
        "#     df[col + '_sin'] = np.sin(2 * np.pi * df[col] / df[col].max())\n",
        "#     return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "uCMXraJmRCtU",
        "outputId": "db20fe63-7471-44ce-f67b-e954f6e54793"
      },
      "outputs": [],
      "source": [
        "# 数値カラムの外れ値の影響を減らすためのクリッピング\n",
        "class clip_numeric(base):\n",
        "  def __init__(self,col):\n",
        "    # 数値コラムでなければエラーを出す\n",
        "    if df_train[col].dtype == \"float64\" or df_train[col].dtype == \"int64\":\n",
        "      self.col = col \n",
        "    else:\n",
        "      raise ValueError(\"col is not numeric\")\n",
        "    \n",
        "  def transform(self, input_df):\n",
        "    out_df = pd.DataFrame()\n",
        "    upperbound, lowerbound= np.percentile(input_df[self.col],[1,99])\n",
        "    out_df[self.col]=np.clip(input_df[self.col],upperbound,lowerbound)\n",
        "    assert len(out_df)==len(input_df)\n",
        "    return out_df.add_suffix(\"_clip\")\n",
        "\n",
        "test = clip_numeric(\"work_year\")\n",
        "test.transform(df_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnpH2ZttWb8z",
        "outputId": "53c9ffe6-d132-4af3-a576-f16e3b0c0522"
      },
      "outputs": [],
      "source": [
        "#カテゴリ列について、trainingにしか現れないカテゴリ、もしくはtestにしか現れないカテゴリを可視化\n",
        "from matplotlib_venn import venn2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def check_cat(df_train, df_test, col):\n",
        "  train_s = set(df_train[col].unique())\n",
        "  test_s = set(df_test[col].unique())\n",
        "  fig, ax = plt.subplots(figsize=(6, 4))\n",
        "  venn2(subsets=(train_s, test_s), set_labels=('train', 'test'),ax=ax)\n",
        "  ax.set_title(col)\n",
        "  common = train_s & test_s\n",
        "  print(len(common))\n",
        "  # print(common)\n",
        "  return ax\n",
        "\n",
        "check_cat(df_train, df_test, \"job_title\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "ZHJbfRLZcTbM",
        "outputId": "348417f1-ad45-420a-9d77-2cae3301a053"
      },
      "outputs": [],
      "source": [
        "#カテゴリ特徴量について、トレーニングに一定数以上いない物をまとめてOthersに落とす。\n",
        "class drop_minor_cat_to_others(base):\n",
        "  def __init__(self,col):\n",
        "    self.col = col\n",
        "    self.thresh = 10\n",
        "    \n",
        "  def fit(self, input_df):\n",
        "    output_df = pd.DataFrame()\n",
        "    value_count = input_df[self.col].value_counts()\n",
        "    apply_values = value_count[value_count < self.thresh].index\n",
        "    output_df[self.col] = input_df[self.col].where(~(input_df[self.col].isin(apply_values)),\"Others\")\n",
        "    self.apply_values_ = apply_values\n",
        "    return output_df\n",
        "  \n",
        "  def transform(self, input_df):\n",
        "    output_df = pd.DataFrame()\n",
        "    output_df[self.col] = input_df[self.col].where(~(input_df[self.col].isin(self.apply_values_)),\"Others\")\n",
        "    return output_df\n",
        "\n",
        "test = drop_minor_cat_to_others(\"job_title\")\n",
        "test.fit(df_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tkz8-WGrxxNm",
        "outputId": "76b76308-f97a-4068-b957-6d555d8e3eed"
      },
      "outputs": [],
      "source": [
        "# 主にコンペ用。One_hot_encodingではトレーニングデータとテストデータに共通しない値をOthersに落とす。周辺の特徴量を用いて汎用的な値に直すことも検討\n",
        "class drop_only_train_test_values_to_others(base):\n",
        "  def __init__(self, col):\n",
        "    self.col = col\n",
        "  \n",
        "  def transform(self, input_df):\n",
        "    output_df = pd.DataFrame()\n",
        "    train_values = set(df_train[self.col].unique())\n",
        "    test_values = set(df_test[self.col].unique())\n",
        "    common_values = train_values & test_values\n",
        "    output_df[self.col] = input_df[self.col].where(input_df[self.col].isin(common_values),\"Others\")\n",
        "    return output_df\n",
        "  \n",
        "test = drop_only_train_test_values_to_others(\"job_title\")\n",
        "test.fit(df_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# カテゴリのone_hot_encoding用。コンペ用の変換。\n",
        "# TrainとTestに共通に出現する値のみでone_hot_encodingを行う。\n",
        "# 実務であればTrain側のカテゴリを保有して予測時に適用する形に編集する\n",
        "class one_hot_encoding(base):\n",
        "    def __init__(self, col):\n",
        "        self.col = col\n",
        "        train_values = df_train[self.col].unique()\n",
        "        test_values = df_test[self.col].unique()\n",
        "        self.common_values = set(train_values) & set(test_values)\n",
        "    \n",
        "    def transform(self, input_df):\n",
        "        x = input_df[self.col]\n",
        "        cat = pd.Categorical(x, categories=self.common_values)\n",
        "        out_df = pd.get_dummies(cat)\n",
        "        return out_df\n",
        "    \n",
        "\n",
        "\n",
        "test = one_hot_encoding(\"job_title\")\n",
        "test.fit(df_train)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "id": "pMQYyXIp4Mnp",
        "outputId": "d3ee8d6f-4bff-48f0-eec2-20ea5a834b6e"
      },
      "outputs": [],
      "source": [
        "# テキストの特徴量に対してElastic-netでstacked predictionでメタ特徴量を作成する。\n",
        "# 分類にするならLogisticRegressionのペナルティを編集してElastic-netに。https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression\n",
        "# Foldを変えるならはここを参照 https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection\n",
        "# 線形モデルを変えるならここを参照 https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model\n",
        "# メトリクスを変えるならここを参照https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import StratifiedKFold, KFold\n",
        "from scipy.sparse import hstack\n",
        "from sklearn.linear_model import ElasticNet,LogisticRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "class text_out_of_fold_prediction(base):\n",
        "  def __init__(self, col):\n",
        "    self.nfolds = 5\n",
        "    self.seed = 71\n",
        "    self.target = \"salary\"\n",
        "    self.col = col\n",
        "    self.models = []\n",
        "    self.regression = True\n",
        "    \n",
        "  def fit(self, input_df):\n",
        "    text_df = input_df[self.col].fillna(\"nan\")\n",
        "    self.tfidf_ = TfidfVectorizer(max_features=10000)\n",
        "    converted_txt = self.tfidf_.fit_transform(text_df)\n",
        "    if self.regression:\n",
        "      fold = KFold(n_splits=self.nfolds, random_state=self.seed, shuffle=True)\n",
        "    else:\n",
        "      fold = StratifiedKFold(n_splits=self.nfolds, random_state=self.seed, shuffle=True)\n",
        "    oof_train = np.zeros(len(input_df))\n",
        "    scores = []\n",
        "    for i, (train_idx, valid_idx) in enumerate(fold.split(input_df[self.col], input_df[self.target])):\n",
        "      train_x, train_y = converted_txt[train_idx], input_df.loc[train_idx, self.target]\n",
        "      valid_x, valid_y = converted_txt[valid_idx], input_df.loc[valid_idx, self.target]\n",
        "      \n",
        "      if self.regression:\n",
        "        clf = ElasticNet(random_state=0)\n",
        "        clf.fit(train_x, train_y)\n",
        "        pred_y = clf.predict(valid_x)\n",
        "        score = mean_squared_error(valid_y, pred_y)\n",
        "      else:\n",
        "        clf = LogisticRegression(penalty='elasticnet',solver='sag')\n",
        "        clf.fit(train_x, train_y)\n",
        "        pred_y = clf.predict_proba(valid_x)[:,1]\n",
        "        score = roc_auc_score(valid_y, pred_y)  \n",
        "      print(f'CV Score of Fold_{i} is {score}')\n",
        "      self.models.append(clf)\n",
        "      scores.append(score)\n",
        "      oof_train[valid_idx]= pred_y\n",
        "    print(f\"mean score is {np.mean(scores)}\")\n",
        "    output_df = pd.DataFrame()\n",
        "    output_df[self.col] = oof_train\n",
        "    return output_df.add_prefix(\"predicted_\")\n",
        "        \n",
        "  def transform(self, input_df):\n",
        "    text_df = input_df[self.col].fillna(\"nan\")\n",
        "    converted_txt = self.tfidf_.transform(text_df)\n",
        "    oof_test = np.zeros(len(input_df))\n",
        "    if self.regression:\n",
        "      for clf in self.models:\n",
        "        oof_test += clf.predict(converted_txt)\n",
        "    else:\n",
        "      for clf in self.models:\n",
        "        oof_test += clf.predict_proba(converted_txt)[:,1]\n",
        "    oof_test /= self.nfolds\n",
        "    output_df = pd.DataFrame()\n",
        "    output_df[self.col] = oof_test\n",
        "    return output_df.add_prefix(\"predicted_\")\n",
        "\n",
        "test = text_out_of_fold_prediction(\"job_title\")\n",
        "test.fit(df_train)\n",
        "test.transform(df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        },
        "id": "q9X7SW-pIPTl",
        "outputId": "f970d2d8-8075-4266-f388-4a56d06f13b4"
      },
      "outputs": [],
      "source": [
        "# # カテゴリ特徴量の変換　https://www.analyticsvidhya.com/blog/2020/08/types-of-categorical-data-encoding/\n",
        "# # https://contrib.scikit-learn.org/category_encoders/\n",
        "# import category_encoders as ce\n",
        "# import warnings\n",
        "# warnings.simplefilter('ignore')\n",
        "\n",
        "# def cat_encode_for_liner(df, df2, col):\n",
        "#   encode = ce.OneHotEncoder(cols = col, handle_unknown = 'error', use_cat_names = True) #初回は初見のカテゴリを調べるために\"error\"で。\n",
        "#   df_tmp = encode.fit_transform(df[col])\n",
        "#   df = pd.concat([df, df_tmp], axis = 1)\n",
        "#   df.drop(columns = col, inplace = True)\n",
        "#   df_tmp = encode.transform(df2[col])\n",
        "#   df2 = pd.concat([df2, df_tmp], axis = 1)\n",
        "#   df2.drop(columns = col, inplace = True)\n",
        "#   return df, df2\n",
        "\n",
        "# for col in lis_cols_cat:\n",
        "#   df_train, df_test = cat_encode_for_liner(df_train, df_test, col)\n",
        "# print(df_train.shape, df_test.shape)\n",
        "# df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "id": "fCO3RBThP7lG",
        "outputId": "56b37fff-98ba-4d46-93bf-e1e1e452bf3a"
      },
      "outputs": [],
      "source": [
        "##　要リファクタリング\n",
        "# #欠損値補完の前に欠損値カウント\n",
        "# def null_count(df):\n",
        "#   df[\"null_count\"] = df.isnull().sum(axis=1)\n",
        "#   return df\n",
        "\n",
        "# df_train = null_count(df_train)\n",
        "# df_test = null_count(df_test)\n",
        "# df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHqmqFi_MCPK",
        "outputId": "7d8c8753-fd6e-4be0-8a8a-11eef8f77fea"
      },
      "outputs": [],
      "source": [
        "## 要修正\n",
        "# #数値型特徴量の欠損値補完を行う。欠損値がある列には欠損フラグの列も追加 #純粋な欠損値だけ見ている。データを確認し、偽装欠損値と見込まれる値が見つかれば別途対応\n",
        "# from sklearn.impute import SimpleImputer\n",
        "\n",
        "# def impute_and_flag(df_train, df_test, col_lis):\n",
        "#   imp_lis = []\n",
        "#   for col in col_lis:\n",
        "#     if df_train[col].isnull().any() == True:\n",
        "#       imp_lis.append(col)\n",
        "#       df_train[col+\"_null\"] = 0\n",
        "#       df_train.loc[df_train[col].isnull(), col+\"_null\"] = 1\n",
        "#       df_test[col+\"_null\"] = 0\n",
        "#       df_test.loc[df_test[col].isnull(), col+\"_null\"] = 1\n",
        "#       imp = SimpleImputer(missing_values = np.nan, strategy = 'median')\n",
        "#       df_train[col] = imp.fit_transform(df_train[[col]])\n",
        "#       df_test[col] = imp.transform(df_test[[col]])\n",
        "#     elif df_train[col].isnull().any() == True:\n",
        "#       print(\"missing values is found in only test data for : \"+ col)\n",
        "#       #欠損値がTestデータにだけ現れるケースはデータを要確認。そもそもその列は使えないかも。\n",
        "#     else:\n",
        "#       pass\n",
        "#   print(\"Imputed :\"+ str(imp_lis))\n",
        "#   return df_train, df_test\n",
        "\n",
        "\n",
        "# df_train, df_test = impute_and_flag(df_train, df_test, lis_cols_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "id": "GOKj4r9NEX65",
        "outputId": "92613b8f-607f-4512-c510-ce9ed3793f15"
      },
      "outputs": [],
      "source": [
        "#数値型特徴量の標準化　https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "class standardize(base):\n",
        "  def __init__(self,col):\n",
        "    self.col = col\n",
        "    self.scaler = StandardScaler()\n",
        "  \n",
        "  def fit(self,input_df):\n",
        "    output_df = pd.DataFrame()\n",
        "    output_df[self.col] = self.scaler.fit_transform(input_df[[self.col]]).ravel()\n",
        "    return output_df.add_prefix(\"std_\")\n",
        "  \n",
        "  def transform(self, input_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    output_df = pd.DataFrame()\n",
        "    output_df[self.col] = self.scaler.transform(input_df[[self.col]]).ravel()\n",
        "    return output_df.add_prefix(\"std_\")\n",
        "\n",
        "test = standardize(\"remote_ratio\")\n",
        "test.fit(df_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_blocks = [*[drop_minor_cat_to_others(col) for col in\n",
        "                    ['work_year', 'experience_level', 'employment_type', 'job_title',\n",
        "       'employee_residence','company_location', 'company_size']],\n",
        "                 *[drop_only_train_test_values_to_others(col) for col in ['work_year', 'experience_level', 'employment_type', 'job_title',\n",
        "       'employee_residence','company_location', 'company_size']],\n",
        "                 *[one_hot_encoding(col) for col in ['work_year', 'experience_level', 'employment_type', 'job_title',] \n",
        "                  ],\n",
        "                 *[standardize(col) for col in [\"remote_ratio\"]]\n",
        "                 ]\n",
        "\n",
        "def run_blocks(input_df, blocks, test=False):\n",
        "    output_df = pd.DataFrame()\n",
        "    for block in blocks:\n",
        "        output_i = block.fit(input_df)\n",
        "        assert len(output_i) == len(input_df)\n",
        "        print(output_i.shape)\n",
        "        output_df = pd.concat([output_df, output_i], axis=1)\n",
        "    return output_df\n",
        "\n",
        "run_blocks(df_train, blocks=feature_blocks)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "id": "01-mg1f3ZnIl",
        "outputId": "55c4b988-6ce0-4068-ea07-d89543b74c01"
      },
      "outputs": [],
      "source": [
        "#パーティショニングとStacked prediction\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "# Foldを変えるならはここを参照 https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection\n",
        "# 線形モデルを変えるならここを参照 https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model\n",
        "# メトリクスを変えるならここを参照https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n",
        "\n",
        "class linear_model_cv_prediction(base):\n",
        "  def __init__(self, col):\n",
        "    self.nfolds = 5\n",
        "    self.seed = 71\n",
        "    self.target = \"salary\"\n",
        "    self.models = []\n",
        "    self.regression = True\n",
        "    self.train_folds = []\n",
        "    self.valid_folds = []\n",
        "    # elasticnet\n",
        "    self.params = [alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
        "           max_iter=1000, normalize=False, positive=False, precompute=False,\n",
        "           random_state=0, selection='cyclic', tol=0.0001, warm_start=False]\n",
        "    \n",
        "    # logistic regression\n",
        "    # self.params = [C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "    #                intercept_scaling=1, l1_ratio=0.5, max_iter=100,\n",
        "    #                multi_class='auto', n_jobs=None, penalty='elasticnet',\n",
        "    #                random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
        "    #                warm_start=False]\n",
        "    \n",
        "  def fit(self, input_df):\n",
        "    if self.regression:\n",
        "      fold = KFold(n_splits=self.nfolds, random_state=self.seed, shuffle=True)\n",
        "    else:\n",
        "      fold = StratifiedKFold(n_splits=self.nfolds, random_state=self.seed, shuffle=True)\n",
        "    \n",
        "    oof_train = np.zeros(len(input_df))\n",
        "    scores = []\n",
        "    for i, (train_idx, valid_idx) in enumerate(fold.split(input_df, input_df[self.target])):\n",
        "      train_x, train_y = input_df[train_idx], input_df.loc[train_idx, self.target]\n",
        "      valid_x, valid_y = input_df[valid_idx], input_df.loc[valid_idx, self.target]\n",
        "      \n",
        "      self.train_folds.append(train_idx)\n",
        "      self.valid_folds.append(valid_idx)\n",
        "      \n",
        "      if self.regression:\n",
        "        clf = ElasticNet(**self.params)\n",
        "        clf.fit(train_x, train_y)\n",
        "        pred_y = clf.predict(valid_x)\n",
        "        score = mean_squared_error(valid_y, pred_y)\n",
        "      else:\n",
        "        clf = LogisticRegression(penalty='elasticnet',solver='sag')\n",
        "        clf.fit(train_x, train_y)\n",
        "        pred_y = clf.predict_proba(valid_x)[:,1]\n",
        "        score = roc_auc_score(valid_y, pred_y)  \n",
        "        \n",
        "      print(f'CV Score of Fold_{i} is {score}')\n",
        "      self.models.append(clf)\n",
        "      scores.append(score)\n",
        "      oof_train[valid_idx]= pred_y\n",
        "    print(f\"mean score is {np.mean(scores)}\")\n",
        "    output_df = pd.DataFrame()\n",
        "    output_df[self.col] = oof_train\n",
        "    return output_df.add_prefix(\"predicted_\")\n",
        "  \n",
        "  def transform(self, input_df):\n",
        "    text_df = input_df[self.col].fillna(\"nan\")\n",
        "    converted_txt = self.tfidf_.transform(text_df)\n",
        "    oof_test = np.zeros(len(input_df))\n",
        "    if self.regression:\n",
        "      for clf in self.models:\n",
        "        oof_test += clf.predict(converted_txt)\n",
        "    else:\n",
        "      for clf in self.models:\n",
        "        oof_test += clf.predict_proba(converted_txt)[:,1]\n",
        "    oof_test /= self.nfolds\n",
        "    output_df = pd.DataFrame()\n",
        "    output_df[self.col] = oof_test\n",
        "    return output_df.add_prefix(\"predicted_\")\n",
        "  \n",
        "\n",
        "df_train_pred, df_test_pred, score_table = linear_model_cv_prediction(df_train, df_train_y, df_test, fold, clf_lis)\n",
        "score_table"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyM3/Kd5X/8Q+Zi+sgr0B8De",
      "include_colab_link": true,
      "mount_file_id": "1lVa8HAdNRCJGE8t5iUJfOVsSbAKgt8qK",
      "name": "liner_model.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "d280a3d7820d8a7cd68b3ac1b6c938b4612fc133bd228f2e7ab871064ed1cce4"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
